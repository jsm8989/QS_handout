\begin{comment}
Let's get started with lecturer 11 second to last lecture.
quickly, we view some things about thermalisation just for five minutes or two minutes
to then talk for ten minutes about something that is not thermalisation,
namely localisation and then go on to start with, the last big topic of the course, namely artificial gauge fields and topology.
OK, so we said last time we said that closed quantum systems cannot verbalise because the shooting at question is in any equation.
However, we also said that they do verbalise where we mean something slightly different to formalisation.
And we said that we know that this huge big wave function of the many buddy system of its thoughts as a pure state will always remain a pure state,
so it cannot Clovelly fully relax into a state and a unitary time evolution.
It's different when you have an open system, of course, but if the system is closed, that cannot happen.
But we said that that's actually interesting intellectually,
but it's not of not much practical consequences because all of the things that
we can measure that we can look at will look exactly a further system.
And the answer is the eye can see the thermalisation hypothesis that basically
says all of these many Asian states will by themselves look failed states.
And it's just that if you have specific superpositions of those as your initial states, they look non-formal.
the example is, if I have a state left plus and left minus right,
then if I take the position of the two, I can create a state that's only left. that describes the the that start in the left hand site.
But I would say that it would spread out over the whole system, of course,
if it can, and I can see that providing states or would you take it into account? this proposition initially makes stuff look non-formal.
The coherence is in the initial state and then we can the finger of thermalisation just as a defacing between
all of those many body eigen states such that when there is no coherence left in the firm in the long term,
limit or coherence is a so chaotic that we can't really see them anymore.
Then you end up with just a mixture of these  a looking eigen states and you get to confirm a lot of the.
And we saw how powerful this is by saying you can take a complex,
two dimensional quantum system and let it expand so you can do something where you have a quantum problem,
it's numerically absolutely intractable, but where we can say that if we assume that the system locally formalises.
And then we just got a slow classical evolution that's driven by gradients, temperature,
chemical potential, so we get hydrodynamics spaghetti fusion equations and so on,
then we can actually take a classical Boltzmann approach and calculate 15 minutes on a mobile phone,
even what you would expect if we get something that looks pretty OK. Forget, by the way, everything happening here it below zero.
This is technical artefacts from the specific way the experiment was done.
We also said that in 2D. Classically speaking, you would expect the 2D system is chaotic and verbalising,
but to guess what you would expect it, the one D system the Newton's Cradle can be an integral system.
it has so many kinds quantities, so many intricacies of motion that it cannot families, allies and it therefore shows a very different.
Regular dynamics.
It's a little bit like, many things, when you say, OK, if I have regular dynamics, it's typically a consequence of I have only one,
then then mechanically or freedom left because everything else is covered by the court of motion.
Like, if you have a planet orbiting the Sun,
you have energy and you have Anglo momentum being conserved and therefore the only thing that you can do the only orbit,
which is the regular orbit that is compatible with these to conserve quantities.
the idea is to have enough conserved quantities to get myself regular. Otherwise, I would be chaotic and feminising.
if you look at this, the quantum system, you could also see that the treaty systems is the blue line here was really the assuring I.
it was showing that if the system is interacting, you get very, very slow.
Diffusive dynamics of the particles almost cannot move because they're colliding all the
time with the other particles and forgetting the memory for getting their initial momentum,
and therefore they never get far. You have a very small diffusion concept where we said that in one day the system is different because the
system is integral and you get a fast ballistic expansion just showing you as an example of these differences.
And this  into cable systems, they are, of course, integral to systems, they are finely tuned.
You have to make sure they all have the same authority exactly one otherwise you lose.
The conserve quantities of the whole system will turn chaotic and verbalising.
in the many very sense, being into quibble seems to be a very special point,
a very special fragile point that you add anything generic to the Hamiltonian,
even if it's small, it would kill that effect and trying to diffuse it again.
\end{comment}

The question today is, is there also a robust alternative to thermalisation? And the answer is \textbf{many-body localisation} (MBL). And this is a way of localisation that was predicted by Anderson and explained away in 1958. And the story is that a single particle in a disordered potential can become localised by the disorder. It's called \textbf{Anderson localisation}. And this is a wave effect. It is not the classical localisation. I mean, there's a classical effect as the classical effect to say, if I take a bowl and I put it down in this lowest point, which does not have the energy to overcome any of the barriers, it's stuck in that valley forever. This is not what we're talking about. We're talking about what's the classical limit? Think about a step in the potential and think about a quantum wave coming in. Then you know, what happens at the step is that some part of the wave function will be transmitted in some part of the wavefunction will be reflected that you can calculate it. And now the next step is conceptually rather simple, but has surprising consequences. Let's just say I have many steps and steps up and steps down. And these happen at random positions. And then you can calculate, of course, what happens at every step you can always say, OK, what is the wave function coming in? Some part gets reflected, some part gets transmitted. And that's that. The story is now that if you want to ask how much of this comes out at the end, then you would say, I have to take the sum of all of those possibilities of those amplitudes, and because the positions of these steps up and down are considered to be random they will all have random phases. And if I have known how many complex numbers with random phases, they will average down to zero. Which basically means that this random potential will localise the particles. And for this argument, we only said that you get some part of the wavefunction being reflected and being transmitted. We did not say how much of it. Even if these steps are arbitrarily small. What this means is that in one dimension, arbitrarily small disorder will localise all of the eigenstates at all of the energies. Because even if your potential is very, very small, the effect is weak in the sense that you get only little of the wave function being reflected. But then if you just make the sum of more and more and more terms, at some point you get back to everything being localised. It's a quantum mechanical interference effect. It's not the classical ball just being trapped in the lowest minimum, it's an effect of the wave scattering all the time. But all of those steps and things in the potential. OK. This was known since the 50s, and this is, of course, the single particle effect because we're just talking about the wavefunction of a single particle so far. 

The question then is, does this localisation survive in interacting systems at finite energy? For decades, people were pretty convinced that, no, this cannot survive. And one of the arguments they gave was an argument that comes from a spectroscopy where there was something called \textbf{collisional dephasing}. The fact is that, OK, I have this  a complicated path that my particle takes. But if the particle on the time collides with another particle that gives you a random phaseshift, that kills the coherence. Another argument was to say, well, if I think about I can also think about this localisation in terms of resonances, I can say there's little orbital here and other orbital there, and I can't really hop from here to here because this little orbital will now have slightly different energies and then have energy mismatch. And therefore I can't hop from here to there. And that's what localises me. The same story in a different picture, in a picture of localised states, not of plane waves. And then the argument would be to say that if I have collisions between particles, I suddenly have an \textbf{exponentially larger Hilbert space} to consider. So it's much more likely they will always find the resonance. I will always find that, OK, I have to go up a little bit here. But if another particle goes down a little bit down on the other site that they collide by doing this, total energy is the concept. We have much, much more freedom.

Nonetheless, it has essentially been agreed to be theoretically possible since 2005 (Basko, Aleiner + Altschuler). 

\begin{comment}
, two big papers, this is one of them came out that on the theory site said that actually,
if you do the vation fury and we sum this to all orders the court,
surely you could sum it up of all of the infinite orders it chose from anybody localisation.
it shows that you have a localised phase even in the presence of interactions.
And this one dimensional systems. And then there have been many, many, many experiments.
Which  showed this effect? And this is not something that has been happening over the last 10 years.
We have also been working on this a lot. It's one of my favourite topics because I this fundamental idea of does everything have to formalise?
What does it not? It's very simple, but it's very deep. In some sense, the story is fundamentally still open.
Because when you want to do numerical simulations, you can only do numerical simulations of small systems.
If you go for very big systems at some point,
there's so much entanglement in this system that you calculations tools if you look at people doing this with matrix poorer states,
the emerging methods matrix with of operators, they can do maybe system size 50 or 100, and they can show that those systems do not verbalise.
But does that mean also an infinitely big system will not formalise? We don't know.
At the same point, you can say quantum simulations, that atoms, you can make a very big system, hundreds of sitelong.
Does this feminise or not? And the answer is, well, we have a finite lifetime in our system.
It's something to be discussed at the very beginning. What it's estimate the stable state atoms want to form the metal,
which means that ultimately we can only keep the system there and to look at the
quantum dynamics over 100 hundred or a thousand or 10000 thousands of topping times.
And there is now some people that say there is indications that you have something
that something that you localisation de case on the LOC logarithm of the time.
log of log of T.
Which means it's in effect, it's so incredibly slow that you would have to wait millions of billions and more of tunnelling times to really see it.
And that, of course, something that nobody can do.
There's also many theories that say, no, this is not true, this is an artefact of how you do your calculation.
We believe this the phase is fundamentally stable, so it's still an interesting debate.
how can we do some experiments on just how we think about this? So.
\end{comment}

OK. Why do we care about this? Well, I already said it. If you have the stability of this localisation and the presence of interactions, you have nonergodic behaviour. You have the potential for long time dynamics. You don't have thermalisation. Statistical mechanics doesn't apply. It's a very different game. And it's, of course, also interesting for quantum computers. Normally your big problem is you put your qubit in an environment, there's always environment and then some information will leak into the environment and just go away and go into this facility and it's lost. But if your environment, if you qubit as many very localised, you don't get this information, spread it as information dilution. You go into the scrambling of quantum information. Even it leaks out and little bit of would stay local. You have much, much more time to recover it. We already said that MBL will require perfect isolation from the environment because everything we've been discussing with her close quantum systems. As soon as I have some coupling to a an environment, then of course I will get thermalised by the environment, whatever I do.

\begin{comment}
How can we do an experiment on this? This was the first experiment actually that was done by us.
You start with disabilities techniques. You put particles only your the even that decides to put them in, even solids, your attach to empty.
And then you just let the system evolve on the tunnelling and the hole. How about Hamiltonian?
And you just ask what happens if you time evolution is organic?
Then it's an issue of charge density wave CDW will be destroyed and you will have an average equal population and even an outsite.
I say on average, because sometimes you measured one sometimes to measure the other, but it's  clear if you're a colleague,
if you go towards the macroeconomic policy angle into even sites on average have as much energy at the outsite than they should in the long run,
not be any thing that distinguishes them. You should lose the memory about you and you should state where you started.
And even if you started off on and thermalisation says you go everywhere.
if I turn this around and I say, well,
if I see a persistent charge density way for all of the times that we can measure, then I have no negative behaviour.
And this we take as a strong indication or proof of localisation because we just don't know of any other non-organic behaviour that can occur.
And of course, the criticism is always, well, you waited a thousand times.
Maybe it's just slow and would have decayed after a million times. And that is the criticism where you have to say, Well, that's a fair criticism.
We can make theoretical arguments why it might or might not apply. But of course, we cannot measure four million tunnelling times yet.
\end{comment}

Experimentally, you can for example prepare an initial state as shown at the top of the figure, dividing the lattice sites up by parity. After free evolution you can look at the charge density waves to determine whether localisation has occured.
[figure - slide]
It is useful to define the imbalance $$I = \frac{N_e-N_o}{N_e+N_o}$$ as a measure of contrast. 
if you want to look at this quantitatively, you can, for instance, look at the imbalance, which is just the contrast. And then an experimental detail is that you don't really create an arbitrary potential. You use something that's called an Aubry-Andr\'e model, so you superimpose two incommensurate lattices. It has the consequence that the localisation transition now does not happen at zero but at a critical point. 

\begin{comment}
The relevant part here is the monitoring particles. They reached a steady state you see very, very fast after, say, 10 tunnelling times.
we could say, let's just look at, say, a factor of three longer 30 tunnelling times and just not plot what we get at Ferdinand
cuddling times as a function of the disorder strength and as a function of the directed.
And this was the first main crawl for meal, which is basically showing that the imbalance that you get after this time is very small.
If you have low this slow down here, everything is blue, everything is aquatic and up here.
Even if I have interactions in this system with positive or attractive interactions, everything is dark red.
stuff is localised, so we have many localisation, at least for those timescales.
Everything is slow. Everything appears to be very localised to direct observation of this effect.
What you can also see is that if you look just at these profile lines, the white lines here,
you see the decay, the non-interactive case is  strongly localised down here already.
But then it just curves upwards a little bit, which means that weakened direction slightly.
Localise your system, make it harder to localise.
this idea that interactions counteract localisation is true in this case, it shifts the critical transition upwards a little bit.
However, there is a difference when you get two very strong interactions, then you get an increase in localisation again.
And this isn't the fact it's very similar to what you had, what we had in the transport experiments last time.
It's the effect that when you go to the hard core limit, there's a mapping from strongly directing hard core particles back to free fermions.
you  expect that this curve must come back down here. It's a reaction behaviour.
this was actually over 20 tumbling times at that point.
And then later on, they were experiments done where this is basically taken up to hundreds and thousands of tunnelling times.
And we looked at the First Order decay processes,
the leading order decay processes we see out of the statement understand that there are technical limitations.
it's a very interesting thing where research is still going on, and I think it would take like.
Probably a decade or so more until we really can say that, yes, there was a very,
very hard proved that measles does really exist or that it does not exist at the moment, it looks it probably does exist in one dimension.
And it's wide open in two dimensions for arguments that go beyond what we can discuss here.
OK. This was the last part of Feminisation, just to show that thermodynamics is extremely powerful,
but not all powerful, the estates that maybe do not families.
And now we can jump over to the or maybe ask us to ask questions on this part before I move over to the final part of the of the course.
Looks no questions. OK, then let's move over and change gears completely for the last part of the course.
\end{comment}

\subsection{Artifical gauge fields}
What we would to do is we would to simulate the effects of a magnetic field first. You know that if you take your classical Hamiltonian for a charged particle in the presence of an electromagnetic field, the Hamiltonian is $H=(p-qA)^2/2m + q\phi$. This magnetic field can be an external magnetic field, just given by an external magnet. It can also be something internal to the material like spin orbit coupling. And ultimately, of course, you would want to also have a quantum theory for this gauge field $A$, like the dynamical gauge theories which are used a lot in quite high energy physics and fundamental interactions and so on, and doing quantum simulations of quantum chromodynamics would be something very, very great. But we are still a little bit off of that. At the moment, we just say we want to simulate the effect of a classical magnetic field that's just externally given by, say, a coil or a magnet. We know how to simulate scalar potentials, for instance, optically. But the vector potential is harder to simulate. 

Let's first look a little bit at what this does before and then we look at how we can simulate it. If you think about the charged particles in the magnetic fields, there's two main ways of thinking. The first one is very classically mechanical is to say there is the Lorentz force $F=q(v \x B)$. If I were charged particle magnetic field and I'm moving in this direction, I get a sideways force that deflects me. And that's of course, the foundation of the cyclotron objects that have electrons in the magnetic field. They will have cyclotron protections around this micromotions. It's also the basis of the Hall effect where the particles pile up on one site of a conductor. tTis is a mechanical effect where you really need the presence of the field if at the position of the particles, there is no magnetic field. There is, however, also a second effect that you have seen in past, in part II electrodynamics and optics. That's the Aharonov-Bohm effect. That's the effect of saying there's a direct coupling between the charge and the vector potential itself. The idea is that if I take a very long, thin solenoid which produces a magnetic field on the inside and of course, the magnetic field lines are close to it, it will come back somehow the other way around. But if I take the approximation of making the solenoid infinitely thin, then the energy field of the outsite goes to zero because the field lines would simply spread over infinitely large areas. And therefore, I have to say magnetic flux in all of the plane compared to the little part in the insite so it can neglect the outer field. And the idea is now that due to this term $qA$ in the Hamiltonian, an electron wave packet split into two parts sent, one left around and one right around this flux here, would pick up an additional phase factor which is given directly by the Aharonov-Bohm phase $\phi_{\AB} = (q/\hbar)\int \int B dS$. And people can make this experiment, you can take electrons have an electron beam, which reflected two points, and you measure the relative phase between the two electron parts here, and you measure that as a function of the magnetic flux to your coil in the middle. You can see it's the phase where you change a sinusoidal with the applied flux. The key thing about this formula is that it's proportional to the magnetic flux and through this enclosed area. But it doesn't care about where the flux is. This is a non-local effect, even if the flux is only in the middle and the particles are well outsite, so they never encountered a flux directly, so they would never have a Lorentz force. Nonetheless, they see this vector potential. And there's a whole bunch of literature in the foundations of quantum mechanics of saying, is it really correct to consider it a non-local interaction or should we look at this in a different way? And it turns out you can ask these questions in the local way, but it's much, much more complicated. It's much, much easier to say there is this vector potential and it has this non-local effect. It's an approximation in the sense, but it's standard. This is what we can do here and now the idea is that this phase, as I said, can be done even if the flux vanishes everywhere along the path. And that's if you want one of the physical motivations of defining the vector potentialy in the first place.

Now you also know which we'll see on the next slide, I guess slide after next.
Is that the vector potential is depend. we cannot say that this is the vector position,
you can measure it so you cannot match the vector potential at some point because it depends on the gauge.
But you can measure the closed loop of the vector potential, and that's how a form phased as close to pentacle is then a gauge independent quantity.
And there's a crucial distinction, which becomes clear in 20 minutes or so. OK, so what is this mean that I just talked about?
Well, you know, that director potentially the magnetic field depends on the vector potential by just being by using the card of the call operator.
And you know, the electric field depends on the vector potentially using its tiny derivative.
And the freedom that you now have is if you say, well, E and B, I know they are committed and they are there now, what can I do to detect a potential?
Well, I can always take the vector potential a and it's to create a created future with so cases killer field.
And the question of that is something that it can act to the vector potential. And if I do this, B and E will be unchanged.
Q aesthetic, so it doesn't do anything to the tag derivative because this is a creative field gradient.
It means that the colour of a created to zero. it does not change to be fit that I measure.
this is the gauge freedom discus wise to this point of say, I used the $\lambda gauge or the cooling gauge or whatever is convenient.
It means that the vector value of the vector potential itself is not so important,
but the ring in the core of the vector potential is still important as a part of physical reality that's measurable observable.
this is a static, we call it gauge for you because it has this great freedom.
That's where the term comes from.
Add more interesting and more complicated than chemical disputes, and there is no first proposal to how they can be simulated of cold atoms.
And people have  seen the microscopic fundamental little effect,
but we're still quite a bit away from doing a full fledged simulation of those things.
Maybe another five years, maybe another decade. OK.
the challenge that we have, the problem that we have is that we have cold atoms, they carry no charge AQ or zero,
which means that all of these expressions, they're nice and funny, but they all zero because there's no charge.
how can we simulate these effects? What can we do? And he had year in fancy language is to say, Well, you need to use synthetic fuels.
You need to do something synthetic, something artificial, that X acts a gate, you put those particles synthetic foods, artificial gauge food.
That's the idea. In reality, what it means is to say, well, we know that if I have a field, my magnetic field somewhere,
I have to say how to form phase two, the quantum particle picks up when it goes around us.
I can't have this directly, but I can have other phases, the berry phase of the payouts phase.
I explained what they on in the future and the next slide.
And we can use them to simulate the effect of this.
if we can generate our interactions in such a way that they give rise to these  phase factors,
then we simulate the effect of this magnetic field and the way we do it.
We called it a synthetic agent. that's the idea.
historically, the first idea of doing this was to start off with the mechanical thought was to say, Well, I have this Lawrence Falls,
which is proportional to queue times v Crosby and this v Crosby is  an interesting structure that we have to reproduce.
One way of reducing that is to say, well, we have to create your task force where we have and times v cross omega.
Omega is the director of rotation. maybe if we take our quantum guess, put it in the container and spin that container,
spin it up to certain angular velocity that would simulate the same quantum gas sitting statically somewhere in the presence of a magnetic field.
And it turns out, lo and behold, this was very successful.
And in 2004, two three four people showed us what, I suppose only confirm any quantum guesses.
Actually, I think for bosons, already ninety nine and the key hallmark feature they could observe was observing
vorticity that you could observe with the quantum gas when you expanded it.
In terms of light shows many of those holds the regular hexagonal pattern of holds the vortices.
it is what is still the same  vortices as you have them in type two superconductors for those that are aware of them.
If another way of them, it's due to the fact that the whole wavefunction is a quantum mechanical wave function.
And if it's a quantum mechanical wave function, it must be well-defined at every point,
which means that if I have some  rotation, I would normally expect that because the particles are moving along this line,
I would expect to have a phase evolution here where the phase of the wave function is different here than here than here in here,
because the creating of the phase gives me the velocity. I would expect that if a phase created here, but at the same time, a no go.
A closed loop. I must come back to the same phase because of the wavefunction must be single valued, which basically means that.
I have a quantisation in here to the phase that I can pick up on a closed loop must be multiple of pipe.
And if I have that, that's fine. But I also have as if I have to snoop snooper, I pick up a phase picture of two.
There must be some point you in the middle. What a phase is not defined. And I can't have that.
what what does Nature do? Well, they just says, what if I put the wave function to zero at that point, then naturally phases multiplied.
And that's what you get, which is what is this? What is this? You get a flux around each vortex, so the particles are  spinning.
Around each of these holes and in the holes, there's no particulates in the middle density zero to the wavefunction vanishes,
so the phase is not well-defined, but it's not a problem.
we have set the quantum gas into rotation, which is exactly the if you want the response you would expect in the cyclotron orbit.
And that would be a sign that you have not  if you want implemented this coyote is possible.
you have similar to the magnetic field, so big success where people then it is to say, OK,
let's look at how many vortices do we get in the quantum system as a function of how fast we spin it?
And it turns out into something that one could calculate, but we don't do it here that for Lomac feeds a low orbit,
low spinning rotations, you know what is he speaks to consiter still sitting, still still the lowest energy state.
Then you get one vortex and you get more vortices and then you get a turbulent pattern, something complicated and then you get no more atoms.
If you spin it too fast, it just doesn't work.
The particles basically spill out because you only have to Coriolis force yourself to centrifugal force.
And it turns out the point where you get many, many vortices is very close to the point where the centrifugal force is just overwhelming a trap.
if you look at what is the magnetic flux that you can simulate, so how many mechanics flux quanta can you put in?
How many vortices can you put in per atom number?
This is a very, very small number, and it's far too small to enter the regime that people might be interested in,
namely the Quantum Hall, which we have two quantum hall effect where you need to have one flux quantum per particle.
it's a nice approach, but it doesn't really work for big systems.
Maybe if you go down to smaller systems that you put three or four particles in a trap,
then you can maybe do a quantum simulation of the institute. What the what effect with this very, very, very small system?
And people are trying that because it's interesting in its own right, but it doesn't help you help us if you want to go on with the big ideas.
OK. this is  the introduction of artificial foods, what we want to do.
And I tell you in the next lecture quite a few ways how we actually do it.
Now I want to step. A little bit and talk a bit more mathematical about geometry and topology,
because these are concepts that we need to understand what's really going on.
the first one that we should talk about is if we have a surphase. Then we should talk we can talk about curvature.
What is the curvature of the surphase? And the main unit for this one is got some curvature, which is the product of the two principle curvature.
if you have, a one dimensional line, it have  a curvature this positive or negative.
And that's what we call the principal curvature of that line.
If you have a two dimensional surphase, what you call the Gaussian curve, which is the product of these two coverages.
full coverage is infinity, the curvatures vanishes and you have you have a flat surphase if what actually is this,
I think this principle, which is the inverse of what I just said. Sorry. this is zero curvature.
This is high curvature. Interesting. The important point by taking the product here is that you have the two sites of the two curvature of the two.
Principal coverage is coming in. if you have something like.
A little Mountain Dew would have positive curvature if you have something a little valley, you would have negative curvature.
But if you have something where you have a where you have a subtle point, then you can also get an upper coverage.
The important point, actually, the important point for us, really is only that curvature or generally geometry,
this is the only thing we really need to remember is a local property. It's defined at this point.
I ask, how is the surphase curved at this point is covered this way or that way?
Or a subtle point? Or is it flat? That's what I'm asking. It's a local property.
And the point is that I can now take this local property and continuously deform it.
If you like, take your orange and you squeeze it. Then the curvature changes at every point.
Do you expect it? No, this is just there.
Two contrasted with topology topology is the study of properties of space that are preserved under such deformations and the continuous deformations.
cluing, bending and stretching a surphase, but not tearing it apart, not cutting it.
Not gluing it together. And then you probably all have seen this cartoon many, many times where you can say that about logically speaking,
though not the lack of coffee is the same thing because you can continuously transform the one into the other.
You see that the key feature here is that both have one hole and to hold a number
of holes as to conserve quantity that does not change doing this dynamics.
And because I said no cheering, no clueing, you can't really change the number of votes,
so the number of votes here is a global property that you cannot change in that way.
It's a protected property. And that's what we call a topological property, a topology.
The other example of this one is the one I gave in the very beginning. It's the movie.
You take this one dimensional slip of paper and you clue it together.
You can a do it directly or can you first have, like, rotated it or rotated it twice included together?
And then once you have done this, you can take the fee, you can stretch it. You can do whatever you want to crumble it up this number.
In this case, a plus minus one rosette. How many holes do I have for how often have I turned the thing?
This number can never change afterwards again. And this number of symptomatically quantised it must be one or two four zero.
It cannot be 1.5. But if I think of gluing this together, I have turned it by turning it twice.
But I cannot have half turned it in. Just doesn't. It doesn't sense.
Doesn't make sense.
examples of those things would be churn numbers, which will explain a lot of things in the economy effect and topological insulators.
And we'll see that in the next slide. these two things are connected.
They they're connected geometry and topology are connected in the colours of the surphases.
But in the case of these classical surphases by the gospel theorem, the mathematical theorem of the digital are so important.
The point is what they've shown is that if I take a two dimensional manifold,
so two dimensional surphase think that's closed so it doesn't have any boundary.
it's  closed onto itself a doughnut or a sphere or anything that.
And then I integrate the curvature over the whole manifold of the whole surphase area with the greatest Gaussian curvature.
It turns out that where we'll get is something of the form two times one minus new Wannier is a natural number two zero one two three four five.
No hope, no fracture, no nothing, it must be a whole natural no.
And it is called the genius of the surphase.
what this basically means now it isn't topological invariant, simply because this number must be an integer and natural number.
what this means is that can take any  surphase that I want. And sort that, according to Mr Prodigy.
There is the surphase is the sphere, the Earth or something the boy that we've seen before, very complicated but have no holds.
The other ones, the donor that have one,
hold the other ones this double donate that have to hold the other ones with three hoses, the creative and so on.
And this classification is robust. Which basically means that you cannot take any of those services.
The doughnut and here or whatnot, and I squeeze it away from it.
I do whatever I want to it as long as it continues and no cheering and accruing, and I cannot change this class.
If I'm in one class, I stay in one class. It's a topological protected property.
Any  local defamation that I do here cannot change the topological property because it's  a global property.
that's how the protection comes about. And this is not OK, a funny piece of mathematics.
The question is, what does this mean in physics? And the first time it really shows up in physics is the integer quantum monolithic.
I guess you are familiar with the setup. You have a two dimensional conductor superconductor.
You have a magnetic field pointing in that direction.
You send the current through here and you measure a voltage in the transverse direction to hold voltage.
And we  know from the what we discussed in the beginning that because of tolerance for all
of the particles are going this way to sort of currents flowing and have this magnetic fields,
they will be drifting off to the site so they will pile up on this site.
I have more eloquence here than a few, so I got an electric field in this direction. That's the whole what they can measure.
And the question is not how is what is the relation between hall voltage and the current that through and the magnetic field?
And that is the day that the famous resigned from quitting.
what you see here is this hard resistance.
it's the alteration of the heart high voltage over the current resentful resistance as a function of the magnetic field in Tesla.
And this is the transverse one, the one that we should first look at.
And the classical hall effect, if you just like, solve these  equations, you say, OK, well, this this term,
because B is bigger, I need to have a bigger e in order to compensate for that, that the current is flowing straight again.
it expects that a good linear relationship between the voltage and the current and indeed for a very small magnetic fields,
you see this linear relationship, this classical relationship.
But then the very surprising thing that they found experimentally this is an experimental crawfish stress is they found this product, they different.
This is one pattern here where, for a whole range of metallic fields, this hard resistance quantised to one very, very, very precise value.
And this. Conductance is high conduct.
So, yes, there's not the inverse of the hall, resistance to conductance is quantised to a very, very simple way.
It's quantised in units of squared over. just the constants, times and C and in that no.
And that's exactly that, that will be quite a churn number.
And this is one of those topological invariant 6.1 mathematical reasons why this number can only be zero, one or two or three.
And that's not physically speaking, extremely surprising at first, and so that's where the main fascination of this whole topic comes from.
No, you would say, OK, I send particulates to it his way. Something happens to them.
Some of them end up on this site. I got a voltage here. That's fine.
But now normally you would save and or change my material a little bit.
Increase the magnetic field a little bit or whatever I do, I change parameters a little bit.
You would expect that the voltage would also change a little bit. It might be a very small change, but could be a change.
And this is  the first time that I see something where I can recall all of the parameters I can swap out,
the one gallium arsenide to another one reflects slightly different doping configurations with more disorder of less disorder with more temperature,
less temperature, and know this number was precisely put. No change that we can detect.
And people have measured this number of many, many digits of precision, and it's really, really, really pissed.
And that's extremely surprising, because all of the physics quantities that we normally have to wheel numbers.
It could be 1.5 for to be 1.5 or one, and any small change to do here will have a change here, but you're not.
It's precisely hard quantised. And that's a big, dirty, heart hot many buddy system.
Well, if you could sort of room temperature, but it's not zero temperature.
And mathematically, we understand it by saying, well,
we know that these  numbers that are politically protected numbers, they can only have value zero, one, two or three.
It's inconceivable that a surphase has 1.5 hold today.
It's inconceivable that this thing has like. They give one point five, it can be one or two.
And then because it's quantised, it has a certain resilience to it.
If I change parameters a little bit, there is nothing it can do. It stays exactly the same until I change it too much.
Then it jumps to the next discrete value. And that's the result of a logically protected quantities.
And just many of those. If I don't have an external magnetic field, but I just have the spin orbit coupling in the material,
I end up with topological insulators, which have similar stories when I look at spin the charge.
If I take topological order I have here and strong interactions, I can also get fractional quantum hall states.
these photos don't have to be one two three four.
They can also be more exotic things one third to fifth and so on when they have strong interactions in the game,
and that's still something that was observed. Maybe a few years after the integer got them, what effect?
But we don't have an analytical wavefunctions and many of those cases, it's still a very complicated problem.
They have some so-called N.E.R.D. Excitations solicitations on top of this fractional quantum hall states.
They they're not bosons of fermions.
There's something else the anionic, which is pretty complicated but has very fascinating properties, for instance, quantum computing.
there's also a lot of interest with that perspective, understanding it's with you. It's better.
in this direction, the holy grail is going to be to observe fractional quantum hall states.
And we're not there yet. We're till the end of the course next weak, we'll make it to the end of the integer quantum.
What effect? That's what has been achieved in the experiment. The fractional quantum dot effect.
Not yet. OK. this is the interesting part about why what topology is interesting and what topological protection actually means in practise.
Now, let's go back a little bit and talk about ways how we can, like, create these  phases that we want to use instead of trying to form phase.
And this is not a big introduction leading up to the concept of the very phase. the people that have seen it to be familiar to you.
First, let's talk about what is a geometric phase with a geometric phase, actually even what is determined.
And the simplest answer is if it takes something called power to transport, which we all have seen in your relativity class.
you basically take a vector two vector here they do transport it along a line and you transport it, touch it locally.
It always keeps the same. The same angle relative to the line that you transported long to you transport in
the parallel manner along the line that if you do this on a flat surphase here,
you transport it this way, this way, this way and you end up of the same back that you had. the dramatic phase in this case is zero.
But if you do this on a curved surphase, say the surphase of a sphere and you see here,
initially, my vector is pointing in the direction of the North Pole.
I move it up along this line and you can see how it transforms into this vector.
And then I go siteways down here again. I keep this angle here, constant all the time.
And then they go back along this line. You can see the director they end up with is not the initial vector.
It's a vector that's rotated by 90 degrees in this case.
And you can see that in this case, the angle of rotation is zero. In this case, it's 90 degrees.
And it turns out that the phase that you get here, what it actually does is it measures the antiquated course and curvature to wonder,
defined earlier and closed by this chosen closed path.
And the phase that you get here does only depend on the geometry of the path that you've taken.
It does not depend on how fast or slow you went along this path, as we knew the geometric phase just depends on the geometry.
It's independent of the speed with which you go to it. OK.
And now let's jump to the real Hamiltonian and see where such a dramatic phase can show up in the time of.
And that's going to be the very phase that's going to be one of the main things that we use to stimulate magnetic fields.
what we have is we have an Hamiltonian age that depends on a whole bunch of parameters are.
it could be that can happen, Tony, that depends on the whatever you let us step to is trying to find directions.
If it's a magnetic field, be exposed by a couple of parameters, we just wait it very generally here.
And those parameters are on principle time dependent so we can change those parameters in time.
we cannot, for instance, change strength and the direction of the magnetic field.
Or if we think about having atoms in the laser field, we can change the tuning of the laser field and the Robbi frequency and time.
I just on here, but I mean, after just to simplify rotation.
I have the recruiting equation, which basically says that the time derivative,
part time derivative of my state society is just as time you get into melatonin time supply of standard.
And now I say that it's assumed that the Smithsonian has island states and it be just wide enough arm is the Earth,
I can see that Hamiltonian for the parameters are. If they were Tony, it depends on parameters to the island states,
but also depend on those parameters for change the opportunity to change the island states.
And NFR is an ideal set of temperature parameter,
so I can ride and between in time state equals just epsilon and the energy of the Untied States times that it's just I can.
I guess that equation.
all of this is mathematically very, very trivial, but the step in the end is  surprising, hence we should go through it carefully.
let me start with an initial state saying I start of zero or my nation state is the end
state at the parameters to to have a time to do so initialise my system and I can state.
And now a two time evolution, I assume a few things I assume just to make life simple.
But the spectrum of Hamiltonian is discrete, so it has 10, 20, 30 states.
There is quite far away from each other and they're not degenerate. And let me also assume that the parameter of T is very adiabatic.
I just changed the parameters for a change so very, very, very slowly.
Then you know that the adiabatic theorem tells you that the state society at the time
T would still be in the end state because it would just follow the EIGEN statement.
I would just theoretically follow the guidance. It could be the crown state could be one of the excited states.
It's an Oregon State and instantaneous. I think states would not change if I don't change R if I change asked low enough.
This carries over to the time of evolution and I we just follow this I can state adiabatic new.
OK. That's a. Does the typical the long time limit slow the limits limit that I have with quantum mechanics?
And for this, I need that the spectrum is discrete enough to degenerate because otherwise it wouldn't work.
OK, so I have this, so I stayed at the stated time. A time T will still be the end of the eigen state.
However, an alternate reality, it will have a phase of evolution. It will be easier to fight something times that state.
I write down explicitly There's a phase five t you.
And though I just plug all of that into the plug, all of that into the shooting equation, and then here's the equation I get.
Let me start here, just left insite of the shooting equation, I H-bomb time, time, evolution of society.
And this gives me two terms because now I have to the product of the Study III,
which depends on T and to have a state and which also implicitly depends on team.
I have to take the time derivative on both. The first one gives me minus h bar fight that usually is five times D I can state,
and this is just the way I take the time the derivative of the i5 team.
And the second one was me, I brought you to the FBI duty of end, it's just the protocol of differentiation.
And this is the neutral. This is the term to be normally don't consiter.
It says with the ideas that can change in time, I get this explicit term in the shooting equation.
Now I start on the hand site. to the Phi Phi Times, end is just the hand site of the shooting equation here.
And then I know that this is just an island state of Victoria, so it is just in time, said.
OK, so now I just take out this part equals this part, and that's on the next slide.
And it basically gives me to this differential equation, you.
It just the recruiting equation in this for the entire state under its evolution, assuming 80 parties, would this basically it by now?
Multiply this with the state and E to the minus I-5 from left just gives me a differential equation for the phase five.
You can see here it's this funny structure appearing where I have a bar and DDT,
and that's basically this dead end with the end here and we at it from the left.
The phase picked troubled. And this now basically gives me the differential equation for my phase evolution.
And this is the main goal of this,
but this is basically telling me is that the phase evolution to the time derivative of the phase of the wave function has two terms to it.
The first one is minus epsilon end of our H-bomb. And this is what we call the dynamical phase.
This is the phase that you are familiar with. If I put the particle in, I can state has a phase evolution of the epsilon over 85 times to you.
And this is this phase of evolution. You did dynamic a phase. The bigger the energy, the faster my phase rotates.
But there's the second term, though here, which is basically the term that comes from this site here.
It's saying it's the time of time.
It's at the start of the state and take the time derivative of the state of the state, change in time I state and then projected back onto the state.
And this is a new term that you probably have not seen before.
And we just write it down here in a slightly different way because we are saying, well,
actually this time evolution is a dramatic time evolution where we changed the parameters on time so we can write this as a gradient and ah,
and then, he added. And the good thing is that this one now creating an artist not depend on the path I particularly take.
It just depends on where I am at all. it's a property of the band structure in the end.
the key thing here is that this is an extra term in a time evolution, and this is due to the time dependence of the Hamiltonian.
And when you think about it, you have a DADT here and a fight out here,
so you can integrate this up and you realise that the second part the phase
evolution indicates due to this part is independent of how fast or how slow you go.
It just depends. Steering integral over this guy here, which is just the derivatives antiquated in parameter space.
And that's why this is a geometric phase depends upon the geometry, and the funny thing is that this is us in some sense,
a calculation that people could have written down in the 20s as soon as the shooting equation that you understand, I can see it.
You could have written the stone. You could have thought about this.
However, it was first written down in all generality by my sir Michael Barry in the 80s.
A a part of quantum mechanics that we just forgot about for 60 years.
And we had an equivalent of this, an optics to punch a luncheon phase, which was found already 20 30 years earlier.
But the whole generality of this was only seen in the 80s. what does this give us?
This gives us a geometric phase, which is now called the berry phase, because Michael Berry is the one who found it.
what we assume for this is we assume that we have a cyclic or cyclic adiabatic evolutionary parameter space.
we assume that if this if you want to my parameter space abstract, I start at some point somewhere else and he goes back to the same point.
If I do this, I say I can say that after iftar time last year, the time that it takes for one loop,
the wave function at time T is the same way Fox has had in the beginning.
Plus a faith factor into the fight. The ideological evolution and the Setoodeh I five, I can write down astronomical phase, plus the very phase.
The chemical phase is just the integral of Epsilon T, so that's the one for the first part of phase evolution.
That's the one that you have to have seen before, and that's the one that, of course, depends on how fast or slow you go through it.
The second one, this contribution here is not a geometric phase, which is independent of the evolution speed.
And that's the story of the very phase,
and we are going to use this very phases next weak to Thursday and the last lecture to understand how we can simulate magnetic fields.
And. Just to give you, like, could I come back to those lights next on Thursday?
But just to give you a quick view on how this looks, how it is going to look is we'll take this thing,
see gradient of see times, OK, and call this the very connexion.
And then we can take the call of this and call it the berry curvature.
That's why I was making so many points about curvature, because this is also a curvature.
And then our cheat sheet, oh, sorry, let me just come back to this light next weak and very.
The cheat sheet is just to say that the structure of this one is the same as you have for the honeymoon phase you bury.
Connexion is going to play a role of a magnetic vector potential in your.
Parameter space. And then the Berry curvature to cut off this will play the role of the magnetic field.
But the thing is that the magnetic field, of course, always lifts in real space,
and there's very faint, very connexion, they lift an arbitrary parameter spaces.
for instance, in the quartz movement, in space, in the free zone of lattice.
And that's where we then going to see a topological structure popping up.
Because we're going to see the debate take this  berry curvature and integrated over the whole prison,
I get an integer gospel theorem and that integer is going to be destroyed, a number which predicts the quantum what effect?
And don't very of the last two slides that were too fast. This is what I'm going to start with on Thursday.
But I wanted to get to that slide that you see where the road is ending. OK.
That's it for today. Thank you very much. Any questions?
Probably not, because there was a lot of fast stuff at the end.
They probably going to have a look at that and then you can ask questions about the slides if you've seen at the beginning of the last lecture.
starting today, there will be the second round of the second round of the supervisions today, tomorrow, Thursday.
You should all have gotten an email from your supervisor when and where it's going to be.
If not, please tell me now, then I can chase them up. And on Friday afternoon, we'll have to join the club again.
That's  taking a step back because the journal club is going to look at the antiferromagnetic in the for.
How about model? And then next weak there's going to be the last round of the supervisions and the.
Join the club and the Join the club is also a big opportunity for you to like,
have looked at the whole course and ask any questions that you might want to ask. Perfect.
Then I'll see you on a Thursday. Thanks a lot.
