So, yeah, welcome back to the quantum simulation class and we today will be moving on from bosons, looking at fermions and how the different Fermi statistics can let us study quantum magnetism. 

Let's start with a recap of what we've seen about fermions before. We can cool fermions down and perform very similar sets of analysis. We've got here the plot of the optical density of the Fermi cloud and you can see that it is slightly different from the Gaussian fit that you might expect to see because you are now fitting with Fermi direct statistics.
[pic]
Remember that one of the differences between fermions and bosons, is that fermions obey the Pauli exclusion principle. With fermions, you're filling up sequential energy levels up to the top of the Fermi sea. And with fermions, we also often want to look at different spin states, and we can separate those spin states out by applying a magnetic field gradient during that period of time of flight and image those and analyse them separately. But that image of the optical density looks a little bit closer to a Gaussian fit than we would actually expect from Fermi Dirac statistics, and that is largely due to the inhomogeneity of the trap. One one thing that we can do to actually extract more useful or more meaningful data from analysing a Fermion system is to play a trick that really boils down to making the local density approximation just in an experimental way. 
[pic- whole second slide]
What you can do here is selectively only image the central portion of the trap, and you do this by applying two hollow beams to your atom cloud, where those beams contain resonant light that will optically pump the atoms from, let's say, the $9/2$ state into the $7/2$ state and this removes the atoms from the main imaging cycle so that you are only able to image this blue central core here, that experiences a much more homogeneous trap, and you get a density measurement that looks like the image on the right, so much more as you'd expect from Fermi statistics. The density has this plateau at a filling of one before falling off as you reach the edge of the Fermi sea.

And one of the pieces of information that we can extract from this analysis is again to look at the entropy of the Fermi gas. 
[pic]
And this is the entropy per particle that is plotted against the \textbf{reduced temperature}, so the temperature divided by the Fermi temperature of the system. In red we have (this is all numerics) the result that you obtain for a harmonic trap, and in blue is the Sommerfeld expansion, which should be familiar from thermal-statistical courses. And it's just here that that entropy per particle is proportional to your reduced temperature. And you can see already from that plot that this has a reasonably good agreement at very low temperatures, so up to about this reduced temperature of around %0.1$, that's a linear approximation is a reasonable one to make. And these are temperatures that are experimentally achievable. From the plot and from the Sommerfeld extension itself, this will give an entropy per particle of approximately $k_B/2$.


Let's think about actually putting fermions in an optical lattice. And to do this, we'll have a reminder of the second quantisation picture where we use creation and annihilation operators on the two sites to describe the atoms in that lattice. 
[eqns - bosonic comms relations]
But with fermions, we have these anticommutations and by exactly the same sets of algebra, we know that 
[eqns - fermionic anticomm]
And this tells us that a wave function is antisymmetric and that the the order in which you apply these operators matters. And this makes defining your basis a lot more complicated because as part of defining the basis, you have to define the order in which these operators are applied. And there is one other important consequence of this, and that is the exclusion principle. If we look at this in the language of second quantisation, we can say that placing two atoms on site $i$ is just $(c_i^\dagger)^2$. But we know from these anticommutation relations that that must be the negative of itself and that therefore $(c_i^\dagger)^2=0$. Our density can be either zero or one on a given lattice site, it cannot be 2. And we know from what you've seen with bosons that those on site interactions only occur if two atoms occupy the same site. Again, we know that if we've got two identical fermions, they can't occupy the same site, therefore they cannot interact via contact interactions. This gives us really quite an uninteresting system until we remember that we can use different spin states to allow two particles to occupy the same lattice site. This then gives us our \textbf{Fermi-Hubbard model} 
[eqn]
which looks a lot the BH Hamiltonian but takes into account the effect of spin. In this Hamiltonian, the spin is described by $\sigma$. And we have three terms again: the hopping term is going to have that spin dependence; likewise for the total atom number and chemical potential; and then our interaction term, which just looks a little bit different to the other two terms in the Hamiltonian because we know that we cannot have, say, two spins occupying the same sites. If we want to consider the same site, we have to consider opposite spins so we don't need to sum over the spins in that term. And we know that for each lattice site, we have four possible states that could correspond to this, so we could have zero atoms in the site, can have one atom a spin up, spin down or we can have two spin-paired atoms per site. And similarly to the language that we've been using for the boson case, we would call that a doublon. Note: this was the original Hubbard model in 1963.

OK, so just before we launch into the possible phases that we can get, let's have a quick recap of the four different parameters that we can use to describe our system. So we'll just take the example of a 3D simple cubic lattice. And we know that for a 1D tight-binding lattice, we'll have a kinetic energy range $-2t<\epsilon < 2t$, in 3-D that extends out to $-6t<\epsilon < 6t$. We want to describe once again the density, and this is just the expectation value of the occupation of a given site. And to do that, we have to account for both the occupation of up and down spins, which tells us about our filling factor. And this is where things get a little bit confusing for fermions, because if you have a filling factor $n=1$ you could call that unity filling; that makes sense, you have one one particle, but you have one particle on a site on which you could have two particles, you could have spin up and spin down. But one particle on that latter site, you could also describe that as half-feeling because of the possible options. 
[eqns - half-filling]
Half of them are filled. That's just one thing to keep in the back of your mind and remember that slightly strange terminology. You can also find the doublon fraction, 
[eqn - doublon fraction]
and that is just the fraction of atoms that occupy sites. Note that this is expressed as a fraction of the total atom number, not a fraction of the total lattice sites. And so you could have, say, sites around the edges if you're considering a harmonic trap has very low occupation and that would skew your statistics. 

This should give us all of the background that we need to consider the possible phases of the Fermi-Hubbard model. So we'll consider in the first instance the non-interactive case where $U=0$. And we also have, in this first example, $T=0$ so we have completely free fermions filling up the Fermi sea one energy level as time. Let's consider adding atoms to the system. Start off with $n=0$. And this is just the vacuum. We have no particles. We have an empty lattice. But as we start to add particles, we get a metallic state, so we know that as we add particles up to this total occupancy level, they're not interacting so we can have one particle per site, we can have two particles per site, zero because there's no cost associated with any double occupation. And so this is a metallic compressible state with $\kappa = \partial n / \partial \mu > 0$. It is a conducting, gapless state because we can always add more particles and we're just then raising the level of the Fermi sea. And then we hit $n=2$. And that is the limit of the allowed states in our system because we can take one spin up, one spin down on each site, and once we've exhausted those states there are none left that we can populate. That becomes a band insulator and it becomes completely incompressible state and an insulating state because there's nothing you can do to that system to force more atoms to occupy the same sites. 

And we can sketch this out, 
[pic - sketch]
so if we look at the occupation as a function of the chemical potential you start off in the vacuum, and then as soon as we reach the range of kinetic energies that we have available in our systems $-6t<\epsilon<6t$ we're able to start populating that lattice, adding in more and more atoms per a site up to that band insulator point of $n=2$. And we get half filling for chemical potential of zero. And we can think about the doublon fraction here, remember that this is the specific case of non-interacting particles. If we look at the doublon fraction we can say that the expectation value
[eqn]
is actually just a product state, those particles don't see each other, there are no correlations between them, which gives us a doublon fraction of $n/2$ in this system. And again, we can plot this, and so it's just a nice linear relationship between the doublon faction and the density. 

But now let's consider the case of strong interactions and in the first instance, strong attractive interactions, $U<0, |U|>>k_BT$. We don't have enough thermal energy to be able to overcome the effects of the interactions. And here we know that all of the particles in our system for form doublons because we can we can lower our energy by having two particles occupying the same site. As soon as you add here, if you start off with one particle in your system, you add another one. The energetically favourable configuration is for those two to occupy the same sites. You add in third, fourth and and they always pair up, so you have a doublon fraction of one. But in the opposite case, you have the exact opposite effect. There is a strong energy cost associated with double occupancy of a single site, so particles will try to singly occupy sites as far as they can and up to a filling factor of one. And that means that our doublon fraction will be zero. For $n\ge1$, they have no choice. They have to start occupying sites because there are no unoccupied sites that they can occupy. And so then we would have some non-zero doublon fraction there. And we can express this in terms of the relationship between the number of atoms and the number of occupied lattice sites. 
[eqn - D_{U=\infty}=\frac{}{}]
As shown in this plot here, 
[pic - top right]
So we get a band insulator for $n=2$, and a MT for $n=1$ which has no doublons in the atomic limit. 

We've seen the metallic phase, we've seen that we can get a MI phase; let's compare the two. For $U=0, t>0$ we have Bloch waves which imply an uncorrelated metal. And let's take the example of a double well potential to illustrate this. We can have particle a particle on the left or the left or the site in this double well.
[eqn - double well state]
And for a given spin state, whether that's up or down, we can have a safe position of left and hand sites and.
The resultant wave function will be proportional to the product of these two positions. And if we expand that out, we see that we have these four options, having both spin up and spin down on the left hand site, spin up and spin down on the hand site or one of each spin on each to the left and hand sites. If we extend that out to a full lattice system rather than just a double well we just have Bloch waves localised across the entire lattice. 

But let's add some interactions in now, because this is going to change the way that the system will respond quite a lot. As we've seen before, if we have non-zero, repulsive interactions, then the double occupation is going to be suppressed by the existence of those interactions. We saw before that gives us a Mott insulator. And if we take this example again of our simple double well potential, then that double occupancy is not allowed anymore, so we lose those two terms and we'll just have the possibility to have spin down on the left site, spin up on the right site and vice versa. This means that if we measure spin down on the left hand site, we know that there is a spin up on the hand site; this is a strongly correlated entangled state. And again, we can expand this out into an entire lattice. And we'll see that we'll get some ordering of spin up and spin down on different lattice sites and the rest of the next half hour will be looking at how the spin up and spin down states are likely to be ordered within the optical lattice.
[eqns - tidy up Metal vs MI slide]

Everything we've just said can be summarised in this plot. 
[pic]
If we start in this region $0<n<1$, that is the metallic state that we described. We distribute our different spins amongst different lattice sites, but there is some correlation between them. As soon as we reach unity filling, we get this Mott insulating  plateau here, because we know that as soon as we add more particles into our system, we're going to have to start having double occupancy; as soon as we start having double occupancy, we pay some energy cost. And so a gap opens and we reach our Mott insulating state. And that Mott insulator lasts until we reach the next kinetic energy range available to our system, $U-6t$, to overcome that energy cost associated with the interaction, so that lets us have another correlated metal, but now that corrugated metal contains some doublons $1<n<2$. Until we reach $n=2$ which is the case that we've seen before of the band insulator. And one important note is that this is, of course, a simplification. Especially around that half filling region. There are a lot of interesting phases that can emerge. The system becomes quite unstable and you can, for instance, get D-Wave superconducting sites. It gives a bit of an idea of why it's interesting.

OK, so. We also want to think about the entropy. And we looked at this last time and we saw that the entropy of our system is proportional to $\log \text{dim}(H) $. And we know that if we've got a single lattice site, we have four possible configurations. But then we have to consider the different limits of energy scales. Again, if we if we consiter this half-filling case and we consiter $U=0$, there is no cost associated with double occupancy and so you have an equal probability of occupying any of those four combinations, so we reached that maximum entropy $k_B \log 4$. But if we have $U>>0$, we saw before that we get an MI. This means that only single occupancy is possible, only spin up or spin down; two possible states, entropy is much lower. This is quite an interesting system, because we can say all of that entropy is associated with the spin, so the spin entropy of our system $=k_B \log 2$, and we have this ordering in our number of particles, whether that's in our case neutral atoms, but in other systems it could be, for instance, electrons. But we have no order in the way that the spins are distributed. 

Let's think about, again, strong, repulsive interactions, but with $U<<k_BT$. Once again, we go back to having four states available because we have the energy available in our system to create these doublon-holon pairs again, so we have the energy available to pay the price of that on site interaction. These can be called thermal pairs, and we lose that charge ordering that we had before. And similar arguments for the attractive case. We know that again, if we just consiter the low temperature limit, we only have doublons if a site is occupied. We either have zero occupation or double occupation, which again gives us a $\log 2$ scaling of our entropy. And it's quite a nice symmetry here between the repulsive and interactive cases where you only have these entropy because of the two possible configurations, even though for the attractive case that's a DH, and for the repulsive case, it's single occupancy spin up or spin down. And again, all of this can be plotted numerically
[pic]
OK, so let's consiter those four cases that we had on the previous slide. We know that for noninteracting we've got a maximum entropy of proportional $\log 4$ and for strong, repulsive we have this $\log 2$, but possibly higher. And then we've got our attractive case as well.  If we can create a region in which we have very low filling, so very low atom density, then we can use that as  a reservoir for all of our excess entropy. We can store a lot of entropy per particle in those low field regions. 

We've got a couple of plots coming up to illustrate some of those ideas. Almost everything that we've seen so far has been at zero temperature. 
[pic MI vs T]
But let's look now at this Mott insulator transition as a function of temperature. As we increase the temperature the distinction between phases slowly gets blurred out by the thermal energy available in our system that is able to slightly overcome some of those restrictions on the occupancy of different sites. And so this Mott insulator signal just gets blurred out as you increase the temperature, and so that's one quite important thing to highlight is that in the fermionic system, the transition is just a crossover, not a phase transition.
[pic- more numerics, simulated density dist]

The cloud size of the atoms can be studied directly, too. And this is a move over into experimental data. 
[pic -cloud size]
In this first case of zero interaction, we can see that this gradient is quite strong, so we have a very compressible cloud. But as we increase $U$ you see this little wiggle here in the data. And that is indicative of the emergence of that Mott insulating phase. 

And one type of this new experiment is the quantum gas microscope that we talked about last time, exactly as for bosons.
[pic - QGM]
This is a single high resolution imaging of the optical lattice, but a parity measurement because of those light assisted collisions during imaging. This can give us some really nice images as we increase interaction strength of our system, and as we increase all our filling. Once again, we see the nice features emerge, the Mott insulating and the metallic regions. One feature that I want to highlight here is this lower row, which gives us the fluctuations in the atom number. As in the boson case, the fluctuations are very low because you've got to pay the energy cost in order to change our atom number on those sites. In the metallic shells around the outsite, the fluctuations are much higher.

Kind of more explicitly looking at looking at the entropy, 
[pic]
we see as we move through the phase diagram between the band insulator to metallic to Mott insulating to vacuum phases as we move from the centre of the centre of the cloud out towards the edge. And once again, we see that it's in this metallic gradient regime that the entropy and those fluctuations start to get very high. Yeah, we've seen  how the entropy can be redistributed deliberately into a region where you have very low density, but you're allowed to have these fluctuations. It's also that you've got to be quite careful if you're working with these metallic shells around the MI to remember that the entropy will be quite high there.

In the last couple of minutes, let's think about how those spins will order themselves. Again, we can take the atomic limit $U>0, t=0, U>>k_BT$. And we know that at halfling, we just have these $n=1$ Fock states. And if you have any localisation. Of atoms from one state to another, that must create a double occupancy and a vacancy. And we've already seen the consequences of that. And we know that that is related to the spins. Remember that the products states of the spins are highly degenerate, so we have all of these different spin configurations in our ground state and they all have equal energies associated with them. But the question is, can we identify a ground state in the system? And that ground state will depend on this hopping term.
[typo on slide - small t instead of large]
We've consitered $t=0$. But now let's consiter some small $t$. We can perform second order perturbation theory in just in the tunnelling term. And the counter-intuitive consequence of this, I guess, is that if we have tunnelling, this means that we can have some slight localisation of atoms from their initial lattice light. And according to the Heisenberg uncertainty principle, this will lower the kinetic energy of that system. If we've got neighbouring spins once been up and down, we have this hopping term, (it's called \textbf{virtual hopping} because we actually just have hopping forward and hopping back very quickly), and this small amount of localisation is enough to lower the energy of the system, the Heisenberg uncertainty principle.
[pic] 
And we know that this is forbidden if those two spins are aligned to each other because of the exclusion principle explicitly forbids this. If we've got two spins of opposite sign on neighbouring sites, we can lower the energy by hopping; if the same spin, we cannot do that. 

And we can make this a little bit more quantitative by directly consitering second order perturbation theory, where we know that the energy shift that will be associated with this, with this hopping,
[eqn - 2PT]
Remember it's a two stage process and that will be proportional to the square of the overlap between our ground state with the hopping Hamiltonian and an excited state divided by the difference in the energies. And this is a little bit more complicated for somewhat more complicated because we actually need degenerate perturbation theory because we know that our excited states are highly degenerate. Let's just simplify this. I'm not worried about what the other terms and say that that will be proportional to $-t^2/U$.
